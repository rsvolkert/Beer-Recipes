---
title: "Using Neural Nets to Create Beer Recipies"
author: "Ryan Volkert and Paul Chong"
date: "5/6/2021"
header-includes:
    - \usepackage{setspace}\doublespacing
output:
  pdf_document: default
  word_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include=FALSE}
library(knitr)
library(tidyverse)
library(ggplot2)
library(readr)
library(reticulate)
```

```{r}
use_python('C:/Users/rvolk/anaconda3/python.exe')
```
\newcommand{\hstart}{ \colorlet{shadecolor}{orange!20}
\begin{shaded} }
\newcommand{\hstop}{  \end{shaded} \colorlet{shadecolor}{gray!10}}


# Abstract

The world of brewing is deep and extensive, both in time and number of recipes available. Colorado is home to the most breweries in the United States (with Fort Collins having the most in a Colorado city). As beer enthusiasts ourselves, our team wanted to see if we were able to replicate the perfect beer recipe based off of previous brews. With a little help from data science and use of neural networks, we wanted to create the perfect beer based off of past recipes and their respective ratings. In this paper, we will go over the data and how we were able to extract recipes from the web. We will then go over the inspirations for our paper. Finally, we will explain the methods used to implement our neural net and provide our final results. 

\newpage

# Introduction

Deep learning has left an impact on the world by solving real-world problems which would have otherwise taken decades to discover or complete. There has been a sharp increase in the use of deep learning thanks to more powerful hardware, larger datasets, and an increase in the population of programmers. These effects have allowed humans to create vast advancements in not only the STEM field, but also the creative world. So we decided to explore the world of beer making, with the help of neural networks.

Using deep learning in for generating recipes is not uncommon. There are several tutorials and repositories online that go through this process. Cocktail recipes and cooking recipes have been generated using recurrent neural networks (Bojar, 2019; Trekhleb, 2020). This specific neural net is useful for this task because of how it makes use of sequential information -- perfect for understanding language (Pascanu et al., 2014).

Brewing is a complex problem. There are several methods of brewing, each with different instructions. Every brew involves some method of getting malt into water, boiling to add hops, and fermenting for a number of weeks (Brewing For Beginners, 2019). The methods vary in how the malt is infused with the water, making it wort.

In all grain brewing, malt is added by steeping grains in hot, but not boiling water, then rinsing them in a process called sparging (BrewingTV, 2015). This is the most complex method, but it can offer the most complex flavor profile. Brewing in a bag (BIAB) is a simpler process where grains are added to a bag in the water (How to Brew In A Bag, 2021). Then there is extract only brewing. This is the simplest method, as you add malt extract directly to your boiling water (Brewing For Beginners, 2019). All of these methods are present in our data, making it a varied and complex set.

# Problem Formulation

With millions of different beer recipes in existence, we thought that there was too much "noise" for everyone to try all the recipes. We thought that there were a lot more beers that tasted bad rather than good. So we wanted to see if we can eliminate the noise a little by creating the best recipe for each type of beer (IPA, sour, porter, etc.).

# Data

As there is not a readily available beer recipe database, we had to scrape the ingredients and formulate our own recipes. We wrote a scraper and headed to Brewer's Friend to gather our data. After compiling the data, we found it to be over 100 MB, much too large for our computing power. We deciced to remove any recipes that did not have at least one review on the site, believing that the unreviewed recipes could not be of much repute. We got the size down to around 13 MB, which would contain plenty of observations for the neural net to learn from. The "recipe.csv" dataset contains different beers and their recipes, where each observation (beer recipe) reported method, boil time, hop utilization, and a number of other columns that contain different steps to combine the different ingredients together.

Since it is important to have an understanding of the model's behavior before compilation, we checked into the brewing methods to see if there was an even spread.

```{r message=FALSE, warning=FALSE}
recipes <- read_csv('Data/recipes.csv')

recipes %>%
  group_by(Method) %>%
  summarize(Count = n()) %>%
  ggplot(aes(Method, Count)) +
  geom_col() +
  ggtitle('Count of Recipes per Brewing Method')
```

Seeing that the recipes are dominated by all grain is not surprising. Most brewers of the caliber to post reputatble recipes will have all grain rigs and be utilizing the freedom that it gives them. This is a problem for the neural network, as it will disproportionately generate all grain recipes, regardless of which style the ingredients call for.

We also wanted to see if brewers were making a specific kind of beer more often. There turned out to be over 100 unique beer styles, but that is because every variation of a style is considered its own style in the data.

```{r message=FALSE, warning=FALSE}
recipes %>%
  group_by(Style) %>%
  summarize(Count = n()) %>%
  arrange(desc(Count)) %>%
  slice_head(n=5) %>%
  ggplot(aes(reorder(Style, -Count), Count)) +
  geom_col() +
  ggtitle('Top 5 Styles') +
  theme(axis.text.x = element_text(angle=45, hjust=1)) +
  xlab('Style')
```

A few styles did stand above the rest. A sizeable portion of recipes are American IPAs. In fact, four out of the top five styles are some kind of pale ale. Since this is a craft brewing site, this is unsurprising. Anecdotally, craft brewers are always making their own style of pale ale. This still can have an effect on the results. Recipes might be more likely to have ingredients and follow methods that correspond with brewing pale ales over anything else.

Finally, we must discuss the structure of our recipes. They were hand-written to have a predictable format, using the ingredients data. They take the form of a beer name, followed by its style, then its brewing methods, its ingredients, and finally, the instructions. This format is reproduced in the final output.

# Neural Network/Modeling

The approach for our model came from the methods outlined by Oleksii Trekhleb (2020), Ilya Sutskever (2013), and Daniel Bojar (2019). We used a recurrent neural network with long short-term memory units. This approach is consistent accross similar problems, so we decided to stick with it. After creating the model, and running for approximated four hours and 73 epochs, it was trained. With a user-defined name, style, and brewing method, we are able to generate an original beer recipe, for better or for worse.

There is also the issue of temperature. Temperature is a measure of how closely we want the results to resemble our data. A temperature of 1.0 will produce interesting results, but it might not make the most sense. Temperatures closer to zero do not allow the model to be as creative. Here is some sample output for an all grain American IPA named Outlet IPA at a temperature of 0.2.

###########################\newline
Attempt: Outlet IPA + 0.2

NAME \newline
Outlet IPA

STYLE \newline
American IPA

METHOD \newline
All Grain 

INGREDIENTS
    
\quad FERMENTABLES
  
\quad\quad 3 lb American - Pale 2-Row\newline
\null\quad\quad 1 lb American - Caramel / Crystal 20L\newline
\null\quad\quad 0.50 lb American - Carapils (Dextrine Malt)\newline
\null\quad\quad 0.50 lb American - Caramel / Crystal 120L

\quad HOPS
	
\quad\quad 1 oz Cascade, Pellet, Boil, 60 min\newline
\null\quad\quad 1 oz Cascade, Pellet, Boil, 15 min\newline
\null\quad\quad 1 oz Cascade, Pellet, Boil, 10 min\newline
\null\quad\quad 1 oz Cascade, Pellet, Boil, 0 min

\quad OTHER
	
\quad\quad 1 tsp Irish Moss, Fining, Boil, 15 min.

\quad YEAST
	
\quad\quad Wyeast - American Ale 1056

INSTRUCTIONS

Santize any equipment that will be in contact with the brew after the boil process. This is very important as we do not want to introduce foreign bacteria to the brew. Brewing santitizer is widely avaialble and labeled with instructions.

1. THE MASH

   Start by milling your grain.\newline
   Heat 1.3 quarts of water for every pound of grain to 145-162 degrees, and add it to the mash tun. Add 1 tsp Calcium Chloride (dihydrate), 1.25 tsp Gypsum,  and 1 tsp Lactic acid.\newline
   Add the grains and stir to make sure that there are no clumps. Make sure that the mash reaches a temperature of 148-158 degrees.\newline
   Allow the mash to rest for about one hour.\newline
   After the rest, raise the mash temperature to 170 degrees by adding near boiling water. Stir well. Leave the mash for another 10 minutes.\newline
   Begin heating the sparge water to 175 degrees.\newline
   Recirculate the mash by siphoning it between two containers and pouring them back down the sides of the mash tun until the wort appears clear.\newline
   Disperse the sparge water over the top of the grain bed while siphoning the wort into the boil kettle at equal rates (1 quart per minute) until you reach 7.5 gallons.
   
2. THE BOIL

   Bring the wort to a rolling boil. Hold there for 60 min.\newline
   With 60 min left, Boil 0.50 oz of Columbus hops.\newline
   With 10 min left, Boil 1 oz of Cascade hops.\newline
   With 5 min left, Boil 1 oz of Cascade hops.\newline
   With 5 min left, Boil 1 each of whirlfloc.\newline
   Complete the following after the boil but before chilling.\newline
   With 30 min left, Whirlpool at 180 °F 1 oz of Centennial hops.\newline
   With 30 min left, Whirlpool at 180 °F 1 oz of Spalt Select hops.\newline
   With 30 min left, Whirlpool at 180 °F 1 oz of Spalt Select hops.\newline
   With 20 min left, Whirlpool at 180 °F 1 oz of Crystal hops.\newline
   With 0 min left, Whirlpool at 180 °F 1 oz of Spalt Select hops.\newline
   With 0 min left, Whirlpool at 180 °F 1 oz of Cascade hops.\newline
   
3. THE CHILL

   Chill the wort to around room tempterature. The method for this depends on your volume.
   
4. FERMENTATION

   Pour the wort into your fermentation vessel. Add water to reach 5.5 gallons Agitate the mixture to bring oxygen into the wort.\newline
   Add your Wyeast - American Ale 1056 to the wort, following the instructions given by the yeast manufacturer.\newline
   Cover your fermenter, fill the airlock to the line with water, and place the airlock in hole in the fermenter lid.\newline
   Fermentation times vary by style of beer. Make sure that you are fermenting for enough time.\newline
   
5. SERVING VESSEL

   You can choose to bottle or keg your beer. Carbonation instructions vary by choice, so make sure you are equipped to carbonate.
   
6. ENJOY!\newline
###########################

# Conclusion

There are obvious issues with the generated recipe. For instance, the hops listed as ingredients are not necessarily the hops that are used in the isntructions. The grains for this recipe seem reasonable, but some of the other recipies were not. We also found that the yeast type given was not always the yeast type used. These are discrepancies that would need to be sorted out by the user or by a larger training set. Filtering the data down to 3,000 recipes might not have been enough to produce reliable results, especially since they were skewed towards all grain American IPAs. Despite its imperfections, we have successfully generated a recipe using a recurrent neural network. It would take a multitude of user filtering and interpretation that these recipies are not likely useful in a real-life setting, yet. With a lot of fine-tuning and a larger dataset, we may yet be able to generate useable brewing recipies.

\newpage

# Bibliography

1. Bojar, D. (2019, January 5). Generating Novel Cocktail Recipes with a Specific Style through Recurrent Neural Networks. Medium. https://towardsdatascience.com/generating-novel-cocktail-recipes-with-a-specific-style-through-recurrent-neural-networks-4339e9168404.

2. Brewing For Beginners - Brewer's Friend. Brewer's Friend | Brewer's Friend is a complete homebrew beer recipe designer with brewing calculators, brew day planner, journal &amp; more. Helping you brew your best, every time! (2019, September 18). https://www.brewersfriend.com/brewing-for-beginners/.

3. BrewingTV, (2015, August 20), All-Grain Brewing 101: The Basics
[Video]. YouTube. https://www.youtube.com/watch?v=AcRXjdlcvKY

4. Britz, D. (2016, July 8). Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs. WildML. http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/.

5. Homebrew Beer Recipes: Browse 200,000+ at Brewer's Friend. Brewer's Friend Beer Brewing Software. (2021). https://www.brewersfriend.com/homebrew-recipes/.

6. How to Brew in a Bag (BIAB). (2021) Homebrew Supply. https://homebrewsupply.com/learn/how-to-brew-in-a-bag-biab/.

7. Pascanu, R., Gulcehre, C., Cho, K., Bengio, Y. (2014) How to Construct Deep Recurrent Neural Networks. Department of Information and Computer Sience, Aalto University School of Medicine.

8. Sutskever, I. (2013) Training Recurrent Neural Networks. Graduate Department of Computer Science, University of Toronto.

9. Trekhleb, O. (2020, July). Generating cooking recipes using TensorFlow and LSTM Recurrent Neural Network: A step-by-step guide. KDnuggets. https://www.kdnuggets.com/2020/07/generating-cooking-recipes-using-tensorflow.html.