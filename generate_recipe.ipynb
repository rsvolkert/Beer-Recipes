{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_recipe.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLQbMnMgfBNk8yGP6uY51z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsvolkert/Beer-Recipes/blob/main/generate_recipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwE8y6Ig_3T3"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X9Q2EdFDYsK"
      },
      "source": [
        "recipes = pd.read_csv('https://raw.githubusercontent.com/rsvolkert/Beer-Recipes/main/Data/recipes.csv')\n",
        "instructions = [recipe for recipe in recipes['recipe']]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zckJqiRcFzTc"
      },
      "source": [
        "STOP = '#'\n",
        "STOP_NAME = 'NAME'\n",
        "STOP_STYLE = 'STYLE'\n",
        "STOP_METHOD = 'METHOD'\n",
        "STOP_INGREDIENTS = 'INGREDIENTS'\n",
        "STOP_INSTRUCTIONS = 'INSTRUCTIONS'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etjn3G00Gb2t"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    char_level=True,\n",
        "    filters='',\n",
        "    lower=False,\n",
        "    split=''\n",
        ")\n",
        "\n",
        "tokenizer.fit_on_texts([STOP])\n",
        "tokenizer.fit_on_texts(instructions)\n",
        "\n",
        "VOCABULARY_SIZE = len(tokenizer.word_counts) + 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvN2v2A8Geez"
      },
      "source": [
        "vectorized = tokenizer.texts_to_sequences(instructions)\n",
        "vectorized_padded_without_stops = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    vectorized,\n",
        "    padding='post',\n",
        "    truncating='post',\n",
        "    value=tokenizer.texts_to_sequences([STOP])[0]\n",
        ")\n",
        "vectorized_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    vectorized_padded_without_stops,\n",
        "    padding='post',\n",
        "    truncating='post',\n",
        "    value=tokenizer.texts_to_sequences([STOP])[0]\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43Yq8uK3GhGA"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(vectorized_padded)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGauU9EyGmoC"
      },
      "source": [
        "def split_input_target(recipe):\n",
        "    input_text = recipe[:-1]\n",
        "    target_text = recipe[1:]\n",
        "    \n",
        "    return input_text, target_text\n",
        "\n",
        "targeted = dataset.map(split_input_target)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p64agJhbGosO"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "SHUFFLE_SIZE = 1000\n",
        "\n",
        "train = targeted.shuffle(SHUFFLE_SIZE).batch(BATCH_SIZE, drop_remainder=True).repeat()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmxkpyPZGqxM"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        batch_input_shape=[batch_size, None]\n",
        "    ))\n",
        "    \n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "        units=rnn_units,\n",
        "        return_sequences=True,\n",
        "        stateful=True,\n",
        "        recurrent_initializer=tf.keras.initializers.GlorotNormal()\n",
        "    ))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dense(vocab_size))\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size=VOCABULARY_SIZE,\n",
        "    embedding_dim=256,\n",
        "    rnn_units=1024,\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyG9l8r4GtBH"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=labels,\n",
        "        y_pred=logits,\n",
        "        from_logits=True\n",
        "    )\n",
        "    \n",
        "    return entropy\n",
        "\n",
        "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss=loss\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdmYgK8rGx6D"
      },
      "source": [
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=5,\n",
        "    monitor='loss',\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "os.makedirs('tmp/checkpoints', exist_ok=True)\n",
        "checkpoint_prefix = os.path.join('tmp/checkpoints', 'ckpt_{epoch}')\n",
        "chckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB81LNmsHx-d"
      },
      "source": [
        "EPOCHS = 500\n",
        "INITIAL_EPOCH = 1\n",
        "STEPS_PER_EPOCH = 1500\n",
        "\n",
        "history = model.fit(\n",
        "    x=train,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    initial_epoch=INITIAL_EPOCH,\n",
        "    callbacks=[early_stopping_callback])\n",
        "\n",
        "model.save('https://raw.githubusercontent.com/rsvolkert/Beer-Recipes/main/recipe_generation_raw.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}